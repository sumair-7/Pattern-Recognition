import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from torch.utils.data import Dataset,DataLoader
import torchvision.transforms as transforms
from  torchvision.datasets import ImageFolder
from torch.autograd import Variable
import cv2
import numpy as np
import os, random,sys







path = '/Users/sumairshaik/Documents/GitHub/Pattern-Recognition/Assignements/HW3/lfw'


transform    = transforms.Compose([transforms.ToTensor()]) 
dataloader = DataLoader(ImageFolder(path, transform,),batch_size=32, shuffle=True)






if torch.backends.mps.is_available():
    device = torch.device("mps")
else:
    print ("MPS device not found.")



for x,y in dataloader:
    x = x[0].permute(1, 2, 0)
    print(x.shape)
    plt.imshow(x)
    break





# Import necessary libraries
import torch

# Get a sample batch from the dataloader
sample_batch, sample_labels = next(iter(dataloader))

# Print dimensions
print("Batch Dimensions:", sample_batch[1:5].shape)
print("Label Dimensions:", sample_labels.shape)









# class AE(nn.Module):
    
#     def __init__(self):
#         super(AE,self).__init__()
        

        

#     def encoder(self,x):
        
        
#     def decoder(self,x):

       
#     def forward(self,x):

       


import torch
import torch.nn as nn

class AE(nn.Module):
    def __init__(self):
        super(AE, self).__init__()

        # Encoder layers
        self.encoder_layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(128),
        )

        # Decoder layers
        self.decoder_layers = nn.Sequential(
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid(),  # Use Sigmoid activation for the last layer to ensure output in the range [0, 1]
            nn.Upsample(size=(250, 250), mode='bilinear', align_corners=False)
        )


    def encoder(self, x):
        return self.encoder_layers(x)

    def decoder(self, x):
        return self.decoder_layers(x)

    def forward(self, x):
        # Forward pass through encoder and decoder functions
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Instantiate the model
ae_model = AE()

# Generate a random input tensor with the same size as your images
input_tensor = torch.randn(1, 3, 250, 250)

# Forward pass
output_tensor = ae_model(input_tensor)

# Print the output shape
print(f"Decoder Output Shape: {output_tensor.shape}")






# model =


import torch
from torch.autograd import Variable
from torch.utils.data import DataLoader

# Assuming you have a DataLoader named 'dataloader' (as you defined earlier)
# Note: Make sure your DataLoader loads images in the same shape as the one you used in the example.

# Create an instance of the AE model
model = AE()

# Use the first image from the batch as a sample
sample_image = sample_batch[0:1]  # Extract the first image (1 batch, 3 channels, height, width)

# Pass the sample image through the model
output = model(sample_image)

# Extract encoder and decoder outputs
encoded_output = model.encoder(sample_image)
decoded_output = model.decoder(encoded_output)

# Print the shapes of encoder and decoder outputs
print("Encoder Output Shape:", encoded_output.shape)
print("Decoder Output Shape:", decoded_output.shape)






# Count the total number of parameters in the model
total_params = sum(p.numel() for p in model.parameters())
print(f"Total Number of Parameters: {total_params}")



loss_function = nn.MSELoss()



import torch.optim as optim

# Define the optimizer
optim = optim.Adam(model.parameters(), lr=0.001)



# optim = 


# loss_function =





# Assuming you have DataLoader and model already defined
# Also, criterion (loss function) and optimizer should be defined as mentioned in the previous response

num_epochs = 10  # You can adjust this based on your training needs

for epoch in range(num_epochs):
    total_loss = 0.0
    
    for batch_data, _ in dataloader:  # Assuming your DataLoader loads both data and labels
        # Zero the gradients
        optim.zero_grad()
        
        # Forward pass
        outputs = model.forward(batch_data)
        
        # Compute the loss
        loss = loss_function(outputs, batch_data)
        
        # Backward pass
        loss.backward()
        
        # Update weights
        optim.step()
        
        total_loss += loss.item()
    
    # Print average loss at the end of each epoch
    avg_loss = total_loss / len(dataloader)
    print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss}")

    # Add any additional monitoring or early stopping criteria here
    
    # Optional: Save the model weights if needed
    # torch.save(autoencoder.state_dict(), 'autoencoder_weights.pth')






# plt.imshow()


import matplotlib.pyplot as plt
import random

# Assuming you have the dataloader and autoencoder already defined

# Set the autoencoder in evaluation mode
model.eval()

# Choose a random image from the dataset
sample_index = random.randint(0, len(dataloader.dataset) - 1)
sample_image, _ = dataloader.dataset[sample_index]

# Add a batch dimension to the sample image
sample_image = sample_image.unsqueeze(0)

# Forward pass through the autoencoder
reconstructed_image = model(sample_image)

# Remove the batch dimension from the reconstructed image
reconstructed_image = reconstructed_image.squeeze(0).detach().numpy()

# Plot the original and reconstructed images
plt.figure(figsize=(8, 4))

# Original Image
plt.subplot(1, 2, 1)
plt.title("Original Image")
plt.imshow(sample_image.squeeze(0).permute(1, 2, 0).numpy())  # Assuming the image is in the format (C, H, W)
plt.axis('off')

# Reconstructed Image
plt.subplot(1, 2, 2)
plt.title("Reconstructed Image")
plt.imshow(reconstructed_image.transpose(1, 2, 0))  # Assuming the image is in the format (C, H, W)
plt.axis('off')

plt.show()






import torch
import matplotlib.pyplot as plt
import random

model.eval()

# Choosing a random image from the dataset
sample_image, _ = dataloader.dataset[random.randint(0, len(dataloader.dataset) - 1)]

# Adding a batch dimension to the sample image
sample_image = sample_image.unsqueeze(0)

# Doing Forward pass through the encoder to get the latent representation
latent_representation = model.encoder(sample_image)

# Adding small normally distributed noise to the latent representation
noise = torch.randn_like(latent_representation) * 0.2  # You can adjust the scale of the noise
noisy_latent_representation = latent_representation + noise

# Using decoder with the noisy latent representation
reconstructed_image_with_noise = model.decoder(noisy_latent_representation)

# Removing the batch dimension from the tensors for plotting
sample_image = sample_image.squeeze(0).permute(1, 2, 0).numpy()
reconstructed_image_with_noise = reconstructed_image_with_noise.squeeze(0).permute(1, 2, 0).detach().numpy()

# Plot the original and reconstructed images with noise
plt.figure(figsize=(12, 4))

# Original Image
plt.subplot(1, 3, 1)
plt.title("Original Image")
plt.imshow(sample_image)
plt.axis('off')

# Reconstructed Image (Noisy Latent)
plt.subplot(1, 3, 2)
plt.title("Reconstructed Image (Noisy Latent)")
plt.imshow(reconstructed_image_with_noise)
plt.axis('off')

plt.show()







