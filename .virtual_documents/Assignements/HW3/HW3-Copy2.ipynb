import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from torch.utils.data import Dataset,DataLoader
import torchvision.transforms as transforms
from  torchvision.datasets import ImageFolder
from torch.autograd import Variable
import cv2
import numpy as np
import os, random,sys







path = '/Users/sumairshaik/Documents/GitHub/Pattern-Recognition/Assignements/HW3/lfw'


transform    = transforms.Compose([transforms.ToTensor()]) 
dataloader = DataLoader(ImageFolder(path, transform,),batch_size=32, shuffle=True)






if torch.backends.mps.is_available():
    device = torch.device("mps")
else:
    print ("MPS device not found.")



for x,y in dataloader:
    x = x[0].permute(1, 2, 0)
    print(x.shape)
    plt.imshow(x)
    break





# Import necessary libraries
import torch

# Get a sample batch from the dataloader
sample_batch, sample_labels = next(iter(dataloader))

# Print dimensions
print("Batch Dimensions:", sample_batch.shape)
print("Label Dimensions:", sample_labels.shape)









import torch
import torch.nn as nn

class AE(nn.Module):
    def __init__(self):
        super(AE, self).__init__()

        # Encoder layers
        self.encoder_layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(128),
        )

        # Decoder layers
        self.decoder_layers = nn.Sequential(
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(16),
            nn.ConvTranspose2d(16, 3, kernel_size=4, stride=1, padding=3),
            nn.Sigmoid()  
        )

    def encoder(self, x):
        return self.encoder_layers(x)

    def decoder(self, x):
        return self.decoder_layers(x)

    def forward(self, x):
        # Forward pass through encoder and decoder functions
        x = self.encoder(x)
        x = self.decoder(x)
        return x






model = AE()


import torch
from torch.autograd import Variable
from torch.utils.data import DataLoader


# Using the first image from the batch as a sample
sample_image = sample_batch[0:1]  # Extracting the first image (1 batch, 3 channels, height, width)

# Extracting encoder and decoder outputs
encoded_output = model.encoder(sample_image)
decoded_output = model.decoder(encoded_output)

# Printing the shapes of encoder and decoder outputs
print("Encoder Output Shape:", encoded_output.shape)
print("Decoder Output Shape:", decoded_output.shape)






# Count the total number of parameters in the model
total_params = sum(p.numel() for p in model.parameters())
print(f"Total Number of Parameters: {total_params}")



loss_function = nn.MSELoss()





import torch.optim as optim

optim = optim.Adam(model.parameters(), lr=0.01)





num_epochs = 10 

for epoch in range(num_epochs):
    total_loss = 0.0
    
    for batch_data, _ in dataloader:  
        # Zero the gradients
        optim.zero_grad()
        
        # Doing Forward pass
        outputs = model.forward(batch_data)

        # Computing the loss
        loss = loss_function(outputs, batch_data)
        
        # Backward pass
        loss.backward()
        
        # Updating weights
        optim.step()
        
        total_loss += loss.item()
    
    # Printing average loss at the end of each epoch
    avg_loss = total_loss / len(dataloader)
    print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss}")

    









import matplotlib.pyplot as plt
import random

model.eval()

# Choosing a random image from the dataset
sample_index = random.randint(0, len(dataloader.dataset) - 1)
sample_image, _ = dataloader.dataset[sample_index]

# Adding a batch dimension to the sample image
sample_image = sample_image.unsqueeze(0)

# Forward pass through the autoencoder
reconstructed_image = model.forward(sample_image)

# Removing the batch dimension from the reconstructed image
reconstructed_image = reconstructed_image.squeeze(0).detach().numpy()

# Plot the original and reconstructed images
plt.figure(figsize=(8, 4))

# Original Image
plt.subplot(1, 2, 1)
plt.title("Original Image")
plt.imshow(sample_image.squeeze(0).permute(1, 2, 0).numpy()) 
plt.axis('off')

# Reconstructed Image
plt.subplot(1, 2, 2)
plt.title("Reconstructed Image")
plt.imshow(reconstructed_image.transpose(1, 2, 0)) 
plt.axis('off')

plt.show()






import torch
import matplotlib.pyplot as plt
import random

model.eval()

# Choosing a random image from the dataset
sample_image, _ = dataloader.dataset[random.randint(0, len(dataloader.dataset) - 1)]

# Adding a batch dimension to the sample image
sample_image = sample_image.unsqueeze(0)

# Doing Forward pass through the encoder to get the latent representation
latent_representation = model.encoder(sample_image)

# Adding small normally distributed noise to the latent representation
noise = torch.randn_like(latent_representation) * 0.2  
noisy_latent_representation = latent_representation + noise

# Using decoder with the noisy latent representation
reconstructed_image_with_noise = model.decoder(noisy_latent_representation)

# Removing the batch dimension from the tensors for plotting
sample_image = sample_image.squeeze(0).permute(1, 2, 0).numpy()
reconstructed_image_with_noise = reconstructed_image_with_noise.squeeze(0).permute(1, 2, 0).detach().numpy()

# Plotting the original and reconstructed images with noise
plt.figure(figsize=(12, 4))

# Original Image
plt.subplot(1, 3, 1)
plt.title("Original Image")
plt.imshow(sample_image)
plt.axis('off')

# Reconstructed Image (with noise)
plt.subplot(1, 3, 2)
plt.title("Reconstructed Image (Noisy Latent)")
plt.imshow(reconstructed_image_with_noise)
plt.axis('off')

plt.show()










