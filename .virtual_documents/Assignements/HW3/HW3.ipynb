import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from torch.utils.data import Dataset,DataLoader
import torchvision.transforms as transforms
from  torchvision.datasets import ImageFolder
from torch.autograd import Variable
import cv2
import numpy as np
import os, random,sys







path = '/Users/sumairshaik/Documents/GitHub/Pattern-Recognition/Assignements/HW3/lfw'


transform    = transforms.Compose([transforms.ToTensor()]) 
dataloader = DataLoader(ImageFolder(path, transform,),batch_size=32, shuffle=True)






if torch.backends.mps.is_available():
    device = torch.device("mps")
else:
    print ("MPS device not found.")



for x,y in dataloader:
    x = x[0].permute(1, 2, 0)
    print(x.shape)
    plt.imshow(x)
    break





# Import necessary libraries
import torch

# sample batch from the dataloader
sample_batch, sample_labels = next(iter(dataloader))

# Print dimensions
print("Batch Dimensions:", sample_batch[0].shape)



# Explaining each dimension
num_channels, height, width = sample_batch[0].size()

print("Number of Channels (Color Channels):", num_channels)
print("Image Height:", height)
print("Image Width:", width)








import torch
import torch.nn as nn

class AE(nn.Module):
    
    def __init__(self):
        super(AE, self).__init__()
        
        # Encoder layers
        self.encoder_layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(128),
        )
        
        # Decoder layers
        self.decoder_layers = nn.Sequential(
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(16),
            nn.ConvTranspose2d(16, 3, kernel_size=4, stride=1, padding=3),
            nn.Sigmoid() 
        )

    def encoder(self, x):
        return self.encoder_layers(x)

    def decoder(self, x):
        return self.decoder_layers(x)

    def forward(self, x):
        # Forward pass through encoder and decoder functions
        x = self.encoder(x)
        x = self.decoder(x)
        return x






model = AE()


import torch
from torch.autograd import Variable
from torch.utils.data import DataLoader

# Using the first image from the batch as a sample
sample_image = sample_batch[0:1] 

print("Sample image shape:", sample_image.shape)

# Extract encoder and decoder outputs
encoded_output = model.encoder(sample_image)
decoded_output = model.decoder(encoded_output)

# Print the shapes of encoder and decoder outputs
print("Encoder Output Shape:", encoded_output.shape)
print("Decoder Output Shape:", decoded_output.shape)






# Count the total number of parameters in the model
total_params = sum(p.numel() for p in model.parameters())
print(f"Total Number of Parameters: {total_params}")



loss_function = nn.MSELoss()





import torch.optim as optim

optim = optim.Adam(model.parameters(), lr=0.001)







num_epochs = 10 

for epoch in range(num_epochs):
    total_loss = 0.0
    
    for batch_data, _ in dataloader:
        # Zero the gradients
        optim.zero_grad()
        
        # Forward pass
        outputs = model(batch_data)

        # Compute the loss
        loss = loss_function(outputs, batch_data)
        
        # Backward pass
        loss.backward()
        
        # Update weights
        optim.step()
        
        total_loss += loss.item()
    
    # Print average loss at the end of each epoch
    avg_loss = total_loss / len(dataloader)
    print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss}")









import matplotlib.pyplot as plt
import random

model.eval()

# Choosing a random image from the dataset
sample_index = random.randint(0, len(dataloader.dataset) - 1)
sample_image, _ = dataloader.dataset[sample_index]

# Adding a batch dimension to the sample image
sample_image = sample_image.unsqueeze(0)

# Doing Forward pass through the autoencoder
reconstructed_image = model(sample_image)

# Removing the batch dimension from the reconstructed image
reconstructed_image = reconstructed_image.squeeze(0).detach().numpy()

# Plot the original and reconstructed images
plt.figure(figsize=(8, 4))

# Original Image
plt.subplot(1, 2, 1)
plt.title("Original Image")
plt.imshow(sample_image.squeeze(0).permute(1, 2, 0).numpy())  # Assuming the image is in the format (C, H, W)
plt.axis('off')

# Reconstructed Image
plt.subplot(1, 2, 2)
plt.title("Reconstructed Image")
plt.imshow(reconstructed_image.transpose(1, 2, 0))  # Assuming the image is in the format (C, H, W)
plt.axis('off')

plt.show()






import torch
import matplotlib.pyplot as plt
import random

model.eval()

# Choosing a random image from the dataset
sample_index = random.randint(0, len(dataloader.dataset) - 1)
sample_image, _ = dataloader.dataset[sample_index]

# Adding a batch dimension to the sample image
sample_image = sample_image.unsqueeze(0)

# Doing Forward pass through the encoder to get the latent representation
latent_representation = model.encoder(sample_image)

# Adding small normally distributed noise to the latent representation
noise = torch.randn_like(latent_representation) * 0.2  # You can adjust the scale of the noise
noisy_latent_representation = latent_representation + noise

# Forward pass through the decoder with the noisy latent representation
reconstructed_image_with_noise = model.decoder(noisy_latent_representation)

# Removing the batch dimension from the tensors for plotting
sample_image = sample_image.squeeze(0).permute(1, 2, 0).numpy()
reconstructed_image_with_noise = reconstructed_image_with_noise.squeeze(0).permute(1, 2, 0).detach().numpy()

# Plotting the original and reconstructed images with noise
plt.figure(figsize=(12, 4))

# Original Image
plt.subplot(1, 3, 1)
plt.title("Original Image")
plt.imshow(sample_image)
plt.axis('off')

# Reconstructed Image (Noisy Latent)
plt.subplot(1, 3, 2)
plt.title("Reconstructed Image (Noisy Latent)")
plt.imshow(reconstructed_image_with_noise)
plt.axis('off')

# Choosing a specific channel or slice of channels from the noisy latent representation for visualization
channel_to_visualize = 0 
latent_channel = noisy_latent_representation.squeeze(0).detach().numpy()[:, :, channel_to_visualize]

# Latent Representation (Noisy)
plt.subplot(1, 3, 3)
plt.title("Noisy Latent Representation")
plt.imshow(latent_channel)
plt.axis('off')

plt.show()




